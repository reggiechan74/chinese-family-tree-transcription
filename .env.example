# API Keys for Language Models
# Get your API keys from:
# - OpenAI: https://platform.openai.com/api-keys
# - Google: https://makersuite.google.com/app/apikey
# - Groq: https://console.groq.com/keys
# - Anthropic: https://console.anthropic.com/account/keys

# Provider API Keys (REQUIRED)
GOOGLE_API_KEY=your-google-api-key-here      # For Google models
OPENAI_API_KEY=your-openai-api-key-here      # For OpenAI models
# GROQ_API_KEY=your-groq-api-key-here        # For Groq models (if needed)
# ANTHROPIC_API_KEY=your-key-here            # For Anthropic models (if needed)

# Default Model Configuration (REQUIRED)
# Used when no specific model is configured for a stage
DEFAULT_MODEL_PROVIDER=google                 # Provider name (google, openai, groq, anthropic)
DEFAULT_MODEL_NAME=gemini-2.0-flash-exp      # Model name from provider's available models
DEFAULT_MODEL_TEMPERATURE=0.7                 # Temperature (0.0-1.0)
DEFAULT_MODEL_TOP_P=0.95                     # Top-p sampling (0.0-1.0)
DEFAULT_MODEL_MAX_TOKENS=0                   # Max tokens (0 for default)

# Stage-Based Model Configuration
# Format for each stage:
# STAGE{N}_MODEL{M}_PROVIDER=provider_name   # Provider of the model
# STAGE{N}_MODEL{M}_NAME=model_name         # Name of the model
# STAGE{N}_MODEL{M}_TEMPERATURE=0.7         # Optional: Temperature (0.0-1.0)
# STAGE{N}_MODEL{M}_TOP_P=0.95              # Optional: Top-p (0.0-1.0)
# STAGE{N}_MODEL{M}_MAX_TOKENS=0            # Optional: Max tokens (0 for default)

# Stage 1 - Initial Transcription (3 models in parallel)
STAGE1_MODEL1_PROVIDER=google
STAGE1_MODEL1_NAME=gemini-2.0-flash-exp
STAGE1_MODEL2_PROVIDER=google
STAGE1_MODEL2_NAME=gemini-1.5-pro
STAGE1_MODEL3_PROVIDER=openai
STAGE1_MODEL3_NAME=gpt-4-turbo

# Stage 2 - Secondary Transcription (3 models in parallel)
STAGE2_MODEL1_PROVIDER=google
STAGE2_MODEL1_NAME=gemini-2.0-flash-exp
STAGE2_MODEL2_PROVIDER=google
STAGE2_MODEL2_NAME=gemini-1.5-pro
STAGE2_MODEL3_PROVIDER=openai
STAGE2_MODEL3_NAME=gpt-4-turbo

# Stage 3 - Initial Review (3 models in parallel)
STAGE3_MODEL1_PROVIDER=google
STAGE3_MODEL1_NAME=gemini-2.0-flash-exp
STAGE3_MODEL2_PROVIDER=google
STAGE3_MODEL2_NAME=gemini-1.5-pro
STAGE3_MODEL3_PROVIDER=openai
STAGE3_MODEL3_NAME=gpt-4-turbo

# Stage 4 - Comprehensive Review (3 models in parallel)
STAGE4_MODEL1_PROVIDER=google
STAGE4_MODEL1_NAME=gemini-2.0-flash-exp
STAGE4_MODEL2_PROVIDER=google
STAGE4_MODEL2_NAME=gemini-1.5-pro
STAGE4_MODEL3_PROVIDER=openai
STAGE4_MODEL3_NAME=gpt-4-turbo

# Final Stages (5-8) - Single Model Per Stage
# These stages use a single model for sequential processing
# By default, uses DEFAULT_MODEL_* settings if not specified

# Stage 5 - Final Transcription
STAGE5_MODEL1_PROVIDER=google
STAGE5_MODEL1_NAME=gemini-2.0-flash-exp

# Stage 6 - Punctuation
STAGE6_MODEL1_PROVIDER=google
STAGE6_MODEL1_NAME=gemini-2.0-flash-exp

# Stage 7 - Translation
STAGE7_MODEL1_PROVIDER=google
STAGE7_MODEL1_NAME=gemini-2.0-flash-exp

# Stage 8 - Commentary
STAGE8_MODEL1_PROVIDER=google
STAGE8_MODEL1_NAME=gemini-2.0-flash-exp

# Available Models by Provider:
#
# Vision + Language Models (Required for Stages 1-2):
#
# OpenAI:
# - gpt-4-turbo
# - gpt-4-vision-preview
#
# Anthropic:
# - claude-3-5-sonnet-20241022
# - claude-3-opus-20240229
#
# Google:
# - gemini-2.0-flash-exp
# - gemini-1.5-pro
# - gemini-exp-1206
#
# Groq:
# - llama-3.2-90b-vision-preview
#
# Language-Only Models (For Stages 3-8):
#
# Google:
# - gemini-pro
#
# Groq:
# - deepseek-r1-distill-llama-70b
# - mixtral-8x7b-32768
# - llama2-70b-4096
# - llama-3.3-70b-versatile

# Stage Flow:
# 1. Stages 1-2: Transcription (3 models in parallel)
#    - Convert image to text
#    - Maintain original formatting
#    - No punctuation or interpretation
#
# 2. Stages 3-4: Review (3 models in parallel)
#    - Analyze transcriptions
#    - Compare versions
#    - Provide recommendations
#
# 3. Stages 5-8: Final Processing (Sequential)
#    - Stage 5: Generate final transcription
#    - Stage 6: Add punctuation
#    - Stage 7: Translate to English
#    - Stage 8: Generate commentary

# Token Tracking Settings (optional)
#TOKEN_TRACKING_ENABLED=true           # Enable token usage tracking
#DISPLAY_REALTIME_USAGE=true          # Show usage in real-time
#SAVE_USAGE_REPORT=true               # Save usage report to file
